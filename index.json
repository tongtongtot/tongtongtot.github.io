[{"content":"\u003ch2 id=\"scperb-single-cell-perturbation-via-style-transfer-based-variational-autoencoder\"\u003eSCPERB: SINGLE-CELL PERTURBATION VIA STYLE TRANSFER-BASED VARIATIONAL AUTOENCODER\u003c/h2\u003e\n\u003cp\u003eTraditional methods for obtaining cellular responses after perturbation are usually labor-intensive and costly, especially when working with rare cells or under severe experimental conditions. Therefore, accurate prediction of cellular responses to perturbations is of great importance in computational biology. To address this problem, some methodologies have been previously developed, including graph-based approaches, vector arithmetic, and neural networks. However, these methods either mix the perturbation-related variances with the cell-type-specific patterns or implicitly distinguish them within black-box models. In this work, we introduce a novel framework, scPerb, to explicitly extract the perturbation-related variances and transfer them from perturbed data to control data. scPerb adopts the style transfer strategy by incorporating a style encoder into the architecture of a variational autoencoder. Such style encoder accounts for the differences in the latent representations between control cells and perturbed cells, which allows scPerb to accurately predict the gene expression data of perturbed cells. Through the comparisons with existing methods, scPerb presents improved performance and higher accuracy in predicting cellular responses to perturbations. Specifically, scPerb not only outperforms other methods across multiple datasets, but also achieves superior R2 values of 0.98, 0.98, and 0.96 on three benchmarking datasets.\u003c/p\u003e\n\u003ch2 id=\"highlights\"\u003eHighlights\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003escPerb merged the concept of style transfer and VAE, resulting in incredible accuracy.\u003c/li\u003e\n\u003cli\u003escPerb outperforms all the existing models of single-cell perturbation prediction\u003c/li\u003e\n\u003cli\u003escPerb is developed and tailored for single-cell perturbation prediction and provided as a ready-to-use open-source software, demonstrating high accuracy and robust performance over existing methods.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"faq\"\u003eFAQ\u003c/h2\u003e\n\u003ch4 id=\"how-can-i-install-scperb\"\u003e\u003cstrong\u003eHow can I install scPerb?\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eYou can download scPerb from our GitHub link:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003egit clone https://github.com/tongtongtot/scperb.git\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003escPerb is built based on PyTorch, tested in Ubuntu 18.04, CUDA environment (cuda 11.6).\u003c/p\u003e\n\u003cp\u003eThe requirement packages include:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eanndata==0.10.3\nmatplotlib==3.7.2\nnumpy==1.24.3\npandas==2.0.3\nscanpy==1.9.6\nscipy==1.11.1\nseaborn==0.12.2\ntorch==2.1.0\ntorchaudio==2.1.0\ntorchvision==0.16.0\ntqdm==4.65.0\nwget==3.2\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eor you can also use the following scripts:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epip install -r requirements.txt\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"i-want-to-try-the-pbmc-demo-can-i-run-scperb-in-one-command-line\"\u003e\u003cstrong\u003eI want to try the PBMC demo, can I run scPerb in one command line?\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eYou can use the following commands:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epython3 scperb.py\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eor please refer to our training tutorial \u003ca href=\"https://github.com/tongtongtot/scperb-tutorial\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"do-i-need-a-gpu-for-running-scperb\"\u003e\u003cstrong\u003eDo I need a GPU for running scPerb?\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003escPerb can run on a standard laptop without GPU. For computational efficiency, we recommend you use a GPU. scPerb could detect whether there is an available GPU or not, so do not worry about this.\u003c/p\u003e\n\u003ch4 id=\"can-i-generate-my-configuration-file-using-the-command-line\"\u003e\u003cstrong\u003eCan I generate my configuration file using the command line?\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eYou can change the default settings in the option.py, while the usage and description are written inside the document.\u003c/p\u003e\n\u003ch4 id=\"link\"\u003e\u003cstrong\u003eLink?\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ca href=\"http://yau-awards.com/uploads/file/20231031/20231031150434_30639.pdf\"\u003eThe paper is under this link.\u003c/a\u003e\u003c/p\u003e\n","description":"","image":"/images/projects/scPerb.jpeg","permalink":"https://tongtongtot.github.io/blogs/scperb/","title":"SCPERB"},{"content":"\u003cp\u003eMy research journey started in May 2022. I joined the Song Lab at Wake Forest University School of Medicine as a high school intern and was fortunate to collaborate with \u003ca href=\"https://qsong-github.github.io/SongLab/\"\u003eProfessor Song\u003c/a\u003e on two research projects. Excited by the application of neural networks in medicine and inspired by Prof. Song’s previous work, I initiated two studies detailed below. I spent, on average, an hour every day during the school year and 8 hours a day during summer on research. Prof. Song primarily specializes in the field of medicine; therefore, I undertook the computer science aspects of my research independently.\u003c/p\u003e\n\u003ch3 id=\"pinet-privileged-information-improve-the-interpretability-and-generalization-of-structural-mri-in-alzheimers-diseasehttpsdlacmorgdoi10114535843713613000\"\u003e\u003ca href=\"https://dl.acm.org/doi/10.1145/3584371.3613000\"\u003ePINet: Privileged Information Improve the Interpretability and generalization of structural MRI in Alzheimer\u0026rsquo;s Disease\u003c/a\u003e\u003c/h3\u003e\n\u003ch4 id=\"introduction\"\u003eIntroduction\u003c/h4\u003e\n\u003cp\u003ePINet is a neural network model devised to detect Alzheimer’s disease from MRI images even before symptoms occur. The research idea focusing on early Alzheimer’s detection originated from my grandpa’s diagnosis of late-stage Alzheimer’s. Prior to his diagnosis, my parents and I had simply attributed his occasional forgetfulness and throwing tantrums to being old and angry over our lack of company, only to realize his condition when it was already too late for any form of intervention. We witnessed his condition develop into dementia and his memory and life were slowly taken away from him. I devoted time to researching the early diagnosis and intervention of Alzheimer’s and realized the potential for neural networks to play a pivotal role.\u003c/p\u003e\n\u003cp\u003eThis paper was accepted (acceptance rate 29%) by the ACM-BCB conference as a rapid-fire paper (top 25% of accepted papers)\u003c/p\u003e\n\u003ch4 id=\"abstract\"\u003eAbstract\u003c/h4\u003e\n\u003cp\u003eThe irreversible and progressive atrophy by Alzheimer’s Disease resulted in continuous decline in thinking and behavioral skills. To date, CNN classifiers were widely applied to assist the early diagnosis of AD and its associated abnormal structures. However, most existing black-box CNN classifiers relied heavily on the limited MRI scans, and used little domain knowledge from the previous clinical findings. In this study, we proposed a framework, named as PINet, to consider the previous domain knowledge as a Privileged Information (PI), and open the black-box in the prediction process. The input domain knowledge guides the neural network to learn representative features and introduced intepretability for further analysis. PINet used a Transformer-like fusion module Privileged Information Fusion (PIF) to iteratively calculate the correlation of the features between image features and PI features, and project the features into a latent space for classification. The Pyramid Feature Visualization (PFV) module served as a verification to highlight the significant features on the input images. PINet was suitable for neuro-imaging tasks and we demonstrated its application in Alzheimer’s Disease using structural MRI scans from ADNI dataset. During the experiments, we employed the abnormal brain structures such as the Hippocampus as the PI, trained the model with the data from 1.5T scanners and tested from 3T scanners. The F1-score showed that PINet was more robust in transferring to a new dataset, with approximatedly 2% drop (from 0.9471 to 0.9231), while the baseline CNN methods had a 29% drop (from 0.8679 to 0.6154). The performance of PINet was relied on the selection of the domain knowledge as the PI. Our best model was trained under the guidance of 12 selected ROIs, major in the structures of Temporal Lobe and Occipital Lobe. In summary, PINet considered the domain knowledge as the PI to train the CNN model, and the selected PI introduced both interpretability and generalization ability to the black box CNN classifiers.\u003c/p\u003e\n\u003ch4 id=\"overview\"\u003eOverview\u003c/h4\u003e\n\u003cp\u003e\u003cimg src=\"/images/projects/graph_pinet.png\" alt=\"img\"\u003e\u003c/p\u003e\n\u003ch4 id=\"results\"\u003eResults\u003c/h4\u003e\n\u003cimg src=\"/images/projects/pinet_results.png\" width = 75% align=\"middle\"/\u003e\n\u003cp\u003eThe accuracy and F1 score of our model is 96% (at the third row)\u003c/p\u003e\n\u003cimg src=\"/images/projects/Pinet-result2.png\" width = 75% align=\"middle\"/\u003e\n\u003cp\u003eThe visualization result of our model.\u003c/p\u003e\n\u003ch3 id=\"scperb-single-cell-perturbation-via-style-transfer-based-variational-autoencoderhttpwwwyau-awardscomuploadsfile2023103120231031150434_30639pdf\"\u003e\u003ca href=\"http://www.yau-awards.com/uploads/file/20231031/20231031150434_30639.pdf\"\u003escPerb: single-cell perturbation via style transfer-based variational autoencoder\u003c/a\u003e\u003c/h3\u003e\n\u003ch4 id=\"introduction-1\"\u003eIntroduction\u003c/h4\u003e\n\u003cp\u003eHoping to leverage my technical skills to analyze single-cell RNA-seq, I proposed a study to generate single-cell perturbation using generative models. At the current stage, it’s challenging to generate sufficient gene expressions in response to different drugs, doses, and treatments for it’s too labor-intensive and costly: computational tools can fill the gap. Lacking a strong background in bioinformatics, I spent a month reading 50+ papers to familiarize myself with the topic. I first learned by rebuilding one of our top benchmarking models published in Nature Methods, scGen, step by step. scGen is already a top-notch model that’s difficult to improve. However, after rewriting the entire TensorFlow codes into PyTorch-style code and successfully regenerating results, I thought of replacing the fixed linear transformation matrix used in the model to possibly achieve higher potentials. After spending months trying different methods, from multi-layers, multi-encoders, different loss functions like Weighted MSE or ZINB loss and even tinkering with other high-performing models like GANs or VQVAE, I found a rather simple solution of applying a style encoder on the original VAE and successfully beat the model’s original performance.\u003c/p\u003e\n\u003ch4 id=\"abstract-1\"\u003eAbstract\u003c/h4\u003e\n\u003cp\u003eTraditional methods for obtaining cellular responses after perturbation are usually labor-intensive and costly, especially when working with rare cells or under se- vere experimental conditions. Therefore, accurate prediction of cellular responses to perturbations is of great importance in computational biology. To address this problem, some methodologies have been previously developed, including graph- based approaches, vector arithmetic, and neural networks. However, these meth- ods either mix the perturbation-related variances with the cell-type-specific pat- terns or implicitly distinguish them within black-box models. In this work, we introduce a novel framework, scPerb, to explicitly extract the perturbation-related variances and transfer them from control data to perturbed data. scPerb adopts the style transfer strategy by incorporating a style encoder into the architecture of a variational for the differences in the latent representations between control cells and perturbed cells, which allows scPerb to accurately predict the gene ex- pression data of perturbed cells. Through the comparisons with existing methods, scPerb presents improved performance and higher accuracy in predicting cellular responses to perturbations. Specifically, scPerb not only outperforms other meth- ods across multiple datasets, but also achieves superior R2 values of 0.98, 0.98, and 0.96 on three benchmarking datasets.\u003c/p\u003e\n\u003ch4 id=\"overview-1\"\u003eOverview\u003c/h4\u003e\n\u003cp\u003e\u003cimg src=\"/images/projects/IMG_00001.jpeg\" alt=\"img\"\u003e\u003c/p\u003e\n\u003ch4 id=\"results-1\"\u003eResults\u003c/h4\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/images/projects/IMG_00001-3.jpeg\" width=41.75%/\u003e\n\u003cimg src=\"/images/projects/IMG_00001-4.jpeg\" width=53.25%/\u003e\n\u003c/figure\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/images/projects/IMG_00001-1.jpeg\" width=46.5%/\u003e\n\u003cimg src=\"/images/projects/IMG_00001-2.jpeg\" width=48.5%/\u003e\n\u003c/figure\u003e","description":"","image":"/images/projects/research.png","permalink":"https://tongtongtot.github.io/blogs/research/","title":"My Research Experience"},{"content":"\u003ch3 id=\"postpartum-depression-care-project\"\u003ePostpartum Depression Care Project\u003c/h3\u003e\n\u003cp\u003eThe \u003cem\u003ePregnant Care free\u003c/em\u003e app is a dedicated platform designed to assist mothers in mitigating the symptoms of postpartum depression. In our app, we hope to build a warm and easy place for you to relax: with places for sharing daily moments, posting emotions, and engaging in forums, you can say whatever you want with other postpartum women or experienced experts. Experts can offer professional guidance through advice posts, enhancing support for regular users. Hope our app could make you feel embraced and guided through your postpartum journey!\u003c/p\u003e\n\u003ch4 id=\"introduction-video\"\u003eIntroduction Video\u003c/h4\u003e\n\u003ciframe height=500 width=888 src=\"/images/projects/PPD-intro.mp4\"\u003e\u003c/iframe\u003e\n\u003ch4 id=\"login-pages\"\u003eLogin pages\u003c/h4\u003e\n\u003cp\u003eThis is the login page of our app.\u003c/p\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/images/projects/login.png\" width=300/\u003e\n\u003cimg src=\"/images/projects/register.png\" width=300/\u003e\n\u003c/figure\u003e\n\u003ch4 id=\"daily\"\u003eDaily\u003c/h4\u003e\n\u003cp\u003eIn this page, you could share your ideas with others freely.\u003c/p\u003e\n\u003cp\u003eAnd you could also find others having the same idea with you.\u003c/p\u003e\n\u003cp\u003eIf there is something you do not want to share with strangers.\u003cbr\u003e\n\u003cem\u003e\u003cstrong\u003eNo problem!\u003c/strong\u003e\u003c/em\u003e\u003cbr\u003e\nYou could just share them with your friends.\u003c/p\u003e\n\u003cp\u003eFriends are added by searching their phone numbers.\u003c/p\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/images/projects/Daily1.png\" width=300/\u003e\n\u003cimg src=\"/images/projects/Daily.png\" width=300/\u003e\n\u003c/figure\u003e\n\u003ch4 id=\"experts-advice\"\u003eExperts advice\u003c/h4\u003e\n\u003cp\u003eIn this section, you would get advice from experts in this field.\u003c/p\u003e\n\u003cp\u003eJust relax, their suggestion and ideas would help you a lot.\u003c/p\u003e\n\u003cimg src=\"/images/projects/expert.png\" width=450/\u003e\n\u003ch4 id=\"playground\"\u003ePlayground\u003c/h4\u003e\n\u003cp\u003eReading and exercising daily could help you feel better.\u003c/p\u003e\n\u003cp\u003eTry to keep on reading and exercising!\u003c/p\u003e\n\u003cp\u003eYou will feel yourself totally different a week later.\u003c/p\u003e\n\u003cfigure\u003e\n\u003cimg src=\"/images/projects/playground1.png\" width=300/\u003e\n\u003cimg src=\"/images/projects/playground2.png\" width=300/\u003e\n\u003c/figure\u003e\n\u003ch4 id=\"download\"\u003eDownload\u003c/h4\u003e\n\u003cp\u003e\u003ca href=\"https://play.google.com/store/apps/details?id=pregproject.pregproject\u0026amp;pli=1\"\u003eGoogle pay\u003c/a\u003e\u003c/p\u003e\n","description":"","image":"/images/projects/PPD.png","permalink":"https://tongtongtot.github.io/blogs/care-free/","title":"Pregnant Carefree"},{"content":"","description":"My gallery :earth_asia:","image":null,"permalink":"https://tongtongtot.github.io/gallery/","title":"Image Gallery"}]